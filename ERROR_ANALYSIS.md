# üîç AN√ÅLISIS COMPLETO DE ERRORES DEL PROYECTO

## üìã RESUMEN EJECUTIVO

El proyecto tiene **m√∫ltiples errores cr√≠ticos** que impiden su funcionamiento. El principal problema es una **inconsistencia en la configuraci√≥n del nombre del cluster HDFS** entre diferentes componentes del sistema.

---

## ‚ùå ERRORES CR√çTICOS POR CAPA

### üî¥ **CAPA 1: INFRAESTRUCTURA HDFS - ERROR CR√çTICO**

#### **Problema Principal: Inconsistencia en el nombre del cluster HDFS**

**Descripci√≥n:**
- El `docker-compose.yml` configura HDFS con el nombre de cluster **`mycluster`** (`hdfs://mycluster`)
- Sin embargo, m√∫ltiples componentes usan **`namenode:9000`** (`hdfs://namenode:9000`)
- Esto causa que los componentes no puedan conectarse correctamente a HDFS

**Ubicaciones del error:**

1. **docker-compose.yml (l√≠neas 111, 162, 209, 234, 259)**
   ```yaml
   - CORE_CONF_fs_defaultFS=hdfs://mycluster  ‚úÖ CORRECTO
   ```

2. **docker-compose.yml - DataNodes (l√≠neas 289, 324, 356)**
   ```yaml
   - CORE_CONF_fs_defaultFS=hdfs://namenode:9000  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster`

3. **docker/init-hdfs.sh (l√≠neas 21, 33-44)**
   ```bash
   hdfs dfs -fs hdfs://namenode:9000  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster`

4. **consumer/src/config.py (l√≠nea 26)**
   ```python
   HDFS_PATH = f"hdfs://{HDFS_NAMENODE}:{HDFS_PORT}{HDFS_BASE_PATH}"
   # Esto genera: hdfs://namenode:9000/...  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster/...`

5. **consumer/src/consumer.py (l√≠neas 25-26)**
   ```python
   .config("spark.hadoop.fs.defaultFS", f"hdfs://{HDFS_NAMENODE}:{HDFS_PORT}")
   # Esto genera: hdfs://namenode:9000  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster`

6. **board/hive_connector.py (l√≠nea 22)**
   ```python
   HDFS_DATA_PATH = f"hdfs://{HDFS_NAMENODE}:{HDFS_PORT}/user/{HDFS_USER}/{PROJECT_NAME}/streaming"
   # Esto genera: hdfs://namenode:9000/...  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster/...`

7. **board/spark_query.py y consumer/spark_query.py (l√≠nea 21)**
   ```python
   .config("spark.hadoop.fs.defaultFS", sys.argv[2] if len(sys.argv) > 2 else "hdfs://namenode:9000")
   # Default incorrecto  ‚ùå INCORRECTO
   ```
   **Deber√≠a ser:** `hdfs://mycluster`

---

### üî¥ **CAPA 2: CONSUMER (SPARK) - ERRORES CR√çTICOS**

#### **Error 1: Configuraci√≥n incorrecta del objeto Config**

**Ubicaci√≥n:** `consumer/src/consumer.py` (l√≠neas 48, 56)

**Problema:**
```python
df_stream = create_kafka_stream(spark, type('Config', (), globals()))
df_transformed = transform_data(df_stream)
query = write_to_hdfs(df_transformed, type('Config', (), globals()), CHECKPOINT_LOCATION)
```

**An√°lisis:**
- `type('Config', (), globals())` es un hack que crea un objeto din√°mico con todas las variables globales
- Esto es fr√°gil y propenso a errores
- Las funciones `create_kafka_stream` y `write_to_hdfs` esperan un objeto `config` con atributos espec√≠ficos
- El objeto creado din√°micamente puede no tener los atributos correctos

**Soluci√≥n:**
- Pasar directamente las variables de configuraci√≥n o crear un objeto Config apropiado
- O mejor: modificar las funciones para usar directamente las variables del m√≥dulo `config`

#### **Error 2: HDFS Path incorrecto en hdfs_writer.py**

**Ubicaci√≥n:** `consumer/src/hdfs_writer.py` (l√≠nea 20)

**Problema:**
```python
hdfs_output_path = f"{config.HDFS_PATH}/streaming"
```

**An√°lisis:**
- `config.HDFS_PATH` viene del objeto din√°mico creado con `type('Config', (), globals())`
- Si el objeto no tiene el atributo correcto, esto fallar√°
- Adem√°s, `HDFS_PATH` ya incluye el path base, por lo que agregar `/streaming` puede duplicar paths

**Soluci√≥n:**
- Usar directamente `HDFS_PATH` del m√≥dulo `config` importado
- O construir el path correctamente

#### **Error 3: Kafka Reader usa objeto config incorrecto**

**Ubicaci√≥n:** `consumer/src/kafka_reader.py` (l√≠neas 33-34)

**Problema:**
```python
.option("kafka.bootstrap.servers", config.KAFKA_BROKER)
.option("subscribe", config.KAFKA_TOPIC)
```

**An√°lisis:**
- Similar al problema anterior, el objeto `config` puede no tener los atributos correctos
- Deber√≠a usar directamente las variables del m√≥dulo `config`

---

### üî¥ **CAPA 3: PRODUCER - ERRORES MENORES**

#### **Error 1: Path del dataset puede no existir**

**Ubicaci√≥n:** `producer/data_loader.py` (l√≠nea 9)

**Problema:**
```python
df = pd.read_csv(DATASET_PATH, sep=';', low_memory=False)
```

**An√°lisis:**
- Si `DATASET_PATH` no existe o es incorrecto, el producer fallar√° sin un mensaje claro
- No hay validaci√≥n previa del archivo

**Soluci√≥n:**
- Agregar validaci√≥n de existencia del archivo antes de leerlo

#### **Error 2: Mensaje de error poco informativo en kafka_client.py**

**Ubicaci√≥n:** `producer/kafka_client.py` (l√≠nea 10)

**Problema:**
```python
bootstrap_servers=KAFKA_BROKER,
```

**An√°lisis:**
- Si `KAFKA_BROKER` es una lista de brokers separados por comas, `KafkaProducer` deber√≠a manejarlo correctamente
- Pero si hay un error de conexi√≥n, el mensaje puede no ser claro

---

### üî¥ **CAPA 4: DASHBOARD - ERRORES CR√çTICOS**

#### **Error 1: Path incorrecto para spark_query.py**

**Ubicaci√≥n:** `board/hive_connector.py` (l√≠nea 37)

**Problema:**
```python
'/app/consumer/spark_query.py',
```

**An√°lisis:**
- El dashboard intenta ejecutar `/app/consumer/spark_query.py` dentro del contenedor `spark-consumer`
- Pero seg√∫n el `docker-compose.yml`, el volumen montado es:
  ```yaml
  - ../consumer:/app/consumer
  ```
- El archivo `spark_query.py` existe tanto en `consumer/` como en `board/`, pero el path puede no ser correcto

**Soluci√≥n:**
- Verificar que el archivo existe en la ruta especificada
- O usar la ruta correcta seg√∫n el volumen montado

#### **Error 2: HDFS URI incorrecta en queries**

**Ubicaci√≥n:** `board/hive_connector.py` (l√≠neas 96, 132, 163, 200)

**Problema:**
```python
FROM parquet.`{HDFS_DATA_PATH}`
# Donde HDFS_DATA_PATH = "hdfs://namenode:9000/..."  ‚ùå INCORRECTO
```

**An√°lisis:**
- Todas las queries usan `HDFS_DATA_PATH` que est√° construido con `namenode:9000`
- Deber√≠a usar `hdfs://mycluster/...`

---

### üî¥ **CAPA 5: CONFIGURACI√ìN DOCKER - ERRORES**

#### **Error 1: DataNodes configurados incorrectamente**

**Ubicaci√≥n:** `docker/docker-compose.yml` (l√≠neas 289, 324, 356)

**Problema:**
```yaml
- CORE_CONF_fs_defaultFS=hdfs://namenode:9000
```

**An√°lisis:**
- Los DataNodes est√°n configurados para conectarse a `namenode:9000` directamente
- Pero el cluster est√° configurado como `hdfs://mycluster` con HA (High Availability)
- Los DataNodes deber√≠an usar `hdfs://mycluster` o la configuraci√≥n correcta para HA

**Soluci√≥n:**
- Cambiar a `hdfs://mycluster` o configurar correctamente para HA

#### **Error 2: Spark Consumer usa configuraci√≥n mixta**

**Ubicaci√≥n:** `docker/docker-compose.yml` (l√≠nea 505)

**Problema:**
- El comando de Spark Consumer tiene configuraci√≥n hardcodeada para `hdfs://mycluster` ‚úÖ
- Pero el c√≥digo Python en `consumer.py` usa `hdfs://namenode:9000` ‚ùå
- Esto causa conflicto entre la configuraci√≥n de Spark y el c√≥digo Python

---

## üîß ERRORES ADICIONALES

### **Error 1: Falta archivo .env**

**Problema:**
- El proyecto referencia `.env` pero no existe en el repositorio
- El `start.sh` intenta crear uno desde `.env.example`, pero ese archivo tampoco existe

**Soluci√≥n:**
- Crear `.env.example` con valores por defecto
- O documentar las variables de entorno necesarias

### **Error 2: Inconsistencia en puertos HDFS**

**Problema:**
- `docker-compose.yml` mapea el puerto 9000 de HDFS a 19000 en el host (l√≠nea 138)
- Pero el c√≥digo usa el puerto 9000 internamente
- Esto puede causar confusi√≥n, pero no es un error cr√≠tico si se usa correctamente

### **Error 3: Checkpoint location puede causar problemas**

**Ubicaci√≥n:** `consumer/src/config.py` (l√≠nea 33-35)

**Problema:**
```python
CHECKPOINT_LOCATION = os.getenv(
    "SPARK_CHECKPOINT_LOCATION",
    f"hdfs://{HDFS_NAMENODE}:{HDFS_PORT}{HDFS_BASE_PATH}/_checkpoints"
)
```

**An√°lisis:**
- Usa `hdfs://namenode:9000` en lugar de `hdfs://mycluster`
- Pero en `docker-compose.yml` se usa `/tmp/spark-checkpoints` (l√≠nea 501)
- Hay inconsistencia entre la configuraci√≥n del c√≥digo y Docker

---

## üìä RESUMEN DE ERRORES POR PRIORIDAD

### üî¥ **CR√çTICOS (Impiden el funcionamiento):**

1. **Inconsistencia en nombre de cluster HDFS** - Afecta a todas las capas
2. **Configuraci√≥n incorrecta de DataNodes** - Impide que HDFS funcione correctamente
3. **Consumer usa objeto Config incorrecto** - Puede causar errores en runtime
4. **Dashboard usa HDFS URI incorrecta** - Las queries fallar√°n

### üü° **IMPORTANTES (Causan problemas pero no bloquean todo):**

1. **Falta archivo .env.example** - Puede causar confusi√≥n en configuraci√≥n
2. **Validaci√≥n de archivos faltante en Producer** - Puede causar errores silenciosos
3. **Inconsistencia en checkpoint location** - Puede causar problemas en reinicios

### üü¢ **MENORES (Mejoras):**

1. **Mensajes de error poco informativos**
2. **Documentaci√≥n de configuraci√≥n**

---

## üéØ SOLUCI√ìN RECOMENDADA

### **Opci√≥n 1: Usar `hdfs://mycluster` en todo el sistema (RECOMENDADO)**

Ventajas:
- Consistente con la configuraci√≥n de HA en docker-compose.yml
- Soporta failover autom√°tico
- M√°s robusto

Cambios necesarios:
1. Cambiar `consumer/src/config.py` para usar `hdfs://mycluster`
2. Cambiar `board/hive_connector.py` para usar `hdfs://mycluster`
3. Cambiar `docker/init-hdfs.sh` para usar `hdfs://mycluster`
4. Cambiar DataNodes en `docker-compose.yml` para usar `hdfs://mycluster`
5. Cambiar `spark_query.py` para usar `hdfs://mycluster` por defecto

### **Opci√≥n 2: Usar `hdfs://namenode:9000` en todo el sistema**

Ventajas:
- M√°s simple, sin configuraci√≥n HA
- M√°s f√°cil de entender

Desventajas:
- Requiere cambiar la configuraci√≥n de HA en docker-compose.yml
- Pierde las ventajas de alta disponibilidad

Cambios necesarios:
1. Cambiar `docker-compose.yml` para usar `hdfs://namenode:9000` en lugar de `hdfs://mycluster`
2. Eliminar configuraci√≥n de HA
3. Simplificar la configuraci√≥n de Spark Consumer

---

## üìù NOTAS ADICIONALES

1. **El c√≥digo del Consumer usa un patr√≥n anti-pattern** con `type('Config', (), globals())`. Deber√≠a refactorizarse para usar imports directos o un objeto Config apropiado.

2. **La configuraci√≥n de HA (High Availability) de HDFS** est√° parcialmente implementada pero no se usa correctamente en el c√≥digo de aplicaci√≥n.

3. **El dashboard depende de ejecutar comandos Docker** dentro de un contenedor, lo cual puede ser problem√°tico en algunos entornos.

4. **Falta validaci√≥n de errores** en varios puntos cr√≠ticos del c√≥digo.

---

## ‚úÖ CHECKLIST DE CORRECCIONES NECESARIAS

- [ ] Corregir nombre de cluster HDFS en `consumer/src/config.py`
- [ ] Corregir nombre de cluster HDFS en `consumer/src/consumer.py`
- [ ] Corregir nombre de cluster HDFS en `board/hive_connector.py`
- [ ] Corregir nombre de cluster HDFS en `docker/init-hdfs.sh`
- [ ] Corregir configuraci√≥n de DataNodes en `docker-compose.yml`
- [ ] Corregir default en `spark_query.py` (tanto en `consumer/` como en `board/`)
- [ ] Refactorizar `consumer.py` para no usar `type('Config', (), globals())`
- [ ] Corregir `hdfs_writer.py` para usar correctamente el path
- [ ] Crear archivo `.env.example`
- [ ] Agregar validaci√≥n de archivos en Producer
- [ ] Unificar configuraci√≥n de checkpoint location

---

**Fecha de an√°lisis:** $(date)
**Versi√≥n del proyecto analizada:** √öltima versi√≥n disponible

