#!/usr/bin/env python3
"""Script para verificar conexi√≥n con Hive Metastore"""
from pyspark.sql import SparkSession
import sys

print("=" * 80)
print("üîç VERIFICANDO HIVE METASTORE")
print("=" * 80)

try:
    # Crear Spark Session con soporte para Hive
    print("\n1Ô∏è‚É£ Creando Spark Session con Hive support...")
    spark = SparkSession.builder \
        .appName("MetastoreTest") \
        .config("spark.sql.warehouse.dir", "hdfs://namenode:9000/user/hive/warehouse") \
        .config("spark.hadoop.fs.defaultFS", "hdfs://namenode:9000") \
        .config("hive.metastore.uris", "thrift://hive-metastore:9083") \
        .enableHiveSupport() \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("ERROR")
    print("‚úÖ Spark Session creada")
    
    # Verificar conexi√≥n intentando listar tablas
    print("\n2Ô∏è‚É£ Verificando conexi√≥n al Metastore (listando tablas)...")
    try:
        tables = spark.sql("SHOW TABLES").collect()
        print(f"‚úÖ Conexi√≥n exitosa! Tablas encontradas: {len(tables)}")
        
        if tables:
            print("\nüìã Tablas registradas:")
            for table in tables:
                table_name = table['tableName'] if 'tableName' in table else table[1]
                database = table['database'] if 'database' in table else table[0]
                print(f"   - {database}.{table_name}")
        else:
            print("   (No hay tablas registradas a√∫n)")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Error al listar tablas: {e}")
        print("   Esto puede ser normal si es la primera vez")
    
    # Verificar si existe la tabla energy_data
    print("\n3Ô∏è‚É£ Verificando si existe la tabla 'energy_data'...")
    try:
        result = spark.sql("SHOW TABLES LIKE 'energy_data'").collect()
        if result:
            print("‚úÖ Tabla 'energy_data' encontrada!")
            
            # Obtener detalles de la tabla
            print("\n4Ô∏è‚É£ Obteniendo detalles de la tabla...")
            desc = spark.sql("DESCRIBE EXTENDED energy_data").collect()
            print("   Columnas y propiedades:")
            for row in desc[:15]:  # Mostrar primeras 15 l√≠neas
                print(f"   {row}")
        else:
            print("‚ö†Ô∏è  Tabla 'energy_data' no encontrada en el Metastore")
            print("   Esto puede significar que el consumer no la ha creado a√∫n")
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Error al verificar tabla: {e}")
    
    # Verificar que puede acceder a los datos en HDFS directamente
    print("\n5Ô∏è‚É£ Verificando acceso a datos en HDFS...")
    try:
        hdfs_path = "hdfs://namenode:9000/user/amalia/energy_data/streaming"
        df = spark.read.parquet(hdfs_path)
        count = df.count()
        print(f"‚úÖ Acceso a HDFS OK! Registros encontrados: {count:,}")
    except Exception as e:
        print(f"‚ùå Error al acceder a HDFS: {e}")
    
    print("\n" + "=" * 80)
    print("‚úÖ Verificaci√≥n completada")
    print("=" * 80)
    
    spark.stop()
    
except Exception as e:
    print(f"\n‚ùå Error general: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

