# ğŸ”§ Correcciones Aplicadas al Docker Compose

## ğŸ“‹ Resumen de Errores Encontrados

### âŒ **Error #1: Carpeta `/data/` no existÃ­a**
**Problema**: El docker-compose.yml intentaba montar `../data:/app/data` pero la carpeta no existÃ­a.

**SoluciÃ³n Aplicada**: 
```bash
mkdir -p data
cp household_power_consumption.txt data/dataset.txt
```

---

### âŒ **Error #2: Ruta incorrecta del Producer**
**Problema**: 
```yaml
volumes:
  - ./producer:/app  # âŒ ./producer no existe en docker/
```

**SoluciÃ³n Aplicada**:
```yaml
volumes:
  - ../producer:/app  # âœ… Ahora apunta a la raÃ­z del proyecto
```

---

### âŒ **Error #3: Faltaban healthchecks**
**Problema**: Los servicios dependientes iniciaban antes de que Kafka y HDFS estuvieran listos.

**SoluciÃ³n Aplicada**:
- Agregado healthcheck a Kafka
- Agregado healthcheck a NameNode
- Agregado healthcheck a DataNode
- Modificado `depends_on` para usar `condition: service_healthy`

---

### âŒ **Error #4: Puerto HDFS no expuesto**
**Problema**: El puerto 9000 de HDFS no estaba mapeado, causando errores de conexiÃ³n.

**SoluciÃ³n Aplicada**:
```yaml
ports:
  - "9870:9870" # Web UI
  - "9000:9000" # HDFS port âœ… AGREGADO
```

---

### âŒ **Error #5: Tiempos de espera muy cortos**
**Problema**: Producer y Consumer intentaban conectarse antes de que los servicios estuvieran listos.

**SoluciÃ³n Aplicada**:
- Producer: sleep 15 (suficiente con healthcheck)
- Consumer: sleep 30 (aumentado de 15 a 30)
- Agregado `restart: on-failure` a ambos

---

## âœ… Mejoras Adicionales Implementadas

1. **Variables de entorno de HDFS**:
   - Agregado `CORE_CONF_fs_defaultFS=hdfs://namenode:9000`

2. **Healthcheck mejorado para NameNode**:
   - Usa curl para verificar Web UI
   - `start_period: 60s` para dar tiempo de inicializaciÃ³n

3. **PolÃ­tica de reintentos**:
   - Agregado `restart: on-failure` a Producer y Consumer
   - Si fallan, Docker los reinicia automÃ¡ticamente

4. **Tiempos de healthcheck optimizados**:
   - Kafka: `start_period: 40s`
   - NameNode: `start_period: 60s`
   - DataNode: `start_period: 40s` (ya existÃ­a)

---

## ğŸš€ Instrucciones de Uso

### 1. Limpiar estado anterior (si existe)
```bash
cd docker
docker compose down -v
```

### 2. Construir imÃ¡genes
```bash
docker compose build
```

### 3. Levantar servicios base primero
```bash
docker compose up -d zookeeper kafka namenode datanode
```

### 4. Esperar a que estÃ©n saludables
```bash
docker ps
# Verificar que STATUS muestre "healthy" para kafka, namenode, datanode
```

### 5. Inicializar HDFS
```bash
./init-hdfs.sh
```

### 6. Levantar resto de servicios
```bash
docker compose up -d
```

### 7. Verificar logs
```bash
docker logs -f producer
docker logs -f spark-consumer
```

---

## ğŸ” VerificaciÃ³n de Funcionamiento

### Verificar Kafka
```bash
# Ver logs
docker logs kafka

# Debe mostrar:
# [KafkaServer id=1] started (kafka.server.KafkaServer)
```

### Verificar HDFS
```bash
# Acceder a Web UI
http://localhost:9870

# Ver directorios
docker exec namenode hdfs dfs -ls /user/amalia/energy_data/
```

### Verificar Producer
```bash
docker logs producer | tail -20

# Debe mostrar:
# ğŸ“¤ Enviado: {"datetime": "...", "global_active_power": ...}
```

### Verificar Consumer
```bash
docker logs spark-consumer | tail -50

# Debe mostrar:
# âœ… Consumer iniciado correctamente
# ğŸ“Š Procesando stream continuamente...
```

---

## ğŸ› Troubleshooting

### Si Producer falla con "No brokers available"
```bash
# Verificar que Kafka estÃ© healthy
docker ps | grep kafka

# Si no estÃ¡ healthy, ver logs
docker logs kafka

# Reiniciar Kafka
docker compose restart kafka
```

### Si Consumer no puede conectar a HDFS
```bash
# Verificar que NameNode estÃ© healthy
docker ps | grep namenode

# Ver Web UI
http://localhost:9870

# Verificar conectividad
docker exec spark-consumer ping namenode -c 3
```

### Si hay errores de permisos en HDFS
```bash
# Re-ejecutar inicializaciÃ³n
./init-hdfs.sh

# O manualmente:
docker exec namenode hdfs dfs -chmod -R 777 /user/amalia
```

---

## ğŸ“Š Arquitectura Final

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Zookeeper  â”‚
â”‚   :2181     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka    â”‚â—„â”€â”€â”€â”€â”€â”¤   Producer   â”‚
â”‚   :9092     â”‚      â”‚  (Python)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Spark Consumer   â”‚
â”‚  :4040 (UI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  NameNode   â”‚â—„â”€â”€â”€â–ºâ”‚  DataNode    â”‚
â”‚  :9870 :9000â”‚     â”‚  :9864       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚    Hive     â”‚
â”‚  Metastore  â”‚
â”‚   :9083     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ… Checklist de ValidaciÃ³n

- [x] Carpeta `data/` creada con `dataset.txt`
- [x] Rutas del Producer corregidas
- [x] Healthchecks agregados a servicios crÃ­ticos
- [x] Puerto 9000 de HDFS expuesto
- [x] Tiempos de espera aumentados
- [x] PolÃ­ticas de reinicio configuradas
- [x] Script `init-hdfs.sh` verificado

---

## ğŸ“ Notas Importantes

1. **Primera ejecuciÃ³n**: Los contenedores tardarÃ¡n ~2-3 minutos en estar completamente listos
2. **Memoria**: Asegurar al menos 8GB RAM disponibles para Docker
3. **Dataset**: El archivo debe estar en `data/dataset.txt` (119 MB aprox)
4. **Logs**: Monitorear los logs de cada servicio durante la primera ejecuciÃ³n

---

Fecha de correcciÃ³n: 2025-10-28
