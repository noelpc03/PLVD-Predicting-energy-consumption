# ğŸ§ª Plan de Pruebas por Capas

Este documento describe las pruebas incrementales por capa para verificar que cada componente funciona correctamente antes de pasar a la siguiente capa.

## ğŸ“Š Arquitectura en Capas

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 6: VISUALIZACIÃ“N                                   â”‚
â”‚   â””â”€ Dashboard (Flask) â†’ Lee de HDFS                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 5: ALMACENAMIENTO                                  â”‚
â”‚   â””â”€ HDFS (Parquet) + Hive Metastore                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 4: CONSUMO                                         â”‚
â”‚   â””â”€ Spark Consumer â†’ Lee de Kafka, escribe a HDFS      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 3: PRODUCCIÃ“N                                      â”‚
â”‚   â””â”€ Producer (Python) â†’ EnvÃ­a a Kafka                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 2: MENSAJERÃA                                      â”‚
â”‚   â””â”€ Kafka (3 brokers) + ZooKeeper                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CAPA 1: INFRAESTRUCTURA BASE                            â”‚
â”‚   â””â”€ ZooKeeper, HDFS (NameNode, DataNodes, JournalNodes)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§ª CAPA 1: Infraestructura Base

### Componentes a probar:
- ZooKeeper
- HDFS NameNode (activo y standby)
- HDFS DataNodes (3 nodos)
- JournalNodes (3 nodos)

### Script de Prueba: `test_layer1_infrastructure.sh`

```bash
#!/bin/bash
# test_layer1_infrastructure.sh - Prueba la infraestructura base

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 1: INFRAESTRUCTURA BASE"
echo "=========================================="
echo ""

# 1. Verificar ZooKeeper
echo "ğŸ“‹ 1. Verificando ZooKeeper..."
docker ps | grep zookeeper
if [ $? -eq 0 ]; then
    echo "âœ… ZooKeeper estÃ¡ corriendo"
    docker exec zookeeper nc -zv localhost 2181
    echo "âœ… Puerto 2181 accesible"
else
    echo "âŒ ZooKeeper NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 2. Verificar NameNode activo
echo "ğŸ“‹ 2. Verificando NameNode activo..."
docker ps | grep namenode
if [ $? -eq 0 ]; then
    echo "âœ… NameNode estÃ¡ corriendo"
    HEALTH=$(docker inspect --format='{{.State.Health.Status}}' namenode 2>/dev/null)
    echo "   Estado de salud: $HEALTH"
    curl -s http://localhost:9870 | grep -q "HDFS" && echo "âœ… Web UI accesible" || echo "âš ï¸  Web UI no accesible"
else
    echo "âŒ NameNode NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 3. Verificar NameNode standby
echo "ğŸ“‹ 3. Verificando NameNode standby..."
docker ps | grep namenode-standby
if [ $? -eq 0 ]; then
    echo "âœ… NameNode standby estÃ¡ corriendo"
    HEALTH=$(docker inspect --format='{{.State.Health.Status}}' namenode-standby 2>/dev/null)
    echo "   Estado de salud: $HEALTH"
else
    echo "âŒ NameNode standby NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 4. Verificar DataNodes
echo "ğŸ“‹ 4. Verificando DataNodes..."
for i in 1 2 3; do
    if [ $i -eq 1 ]; then
        NODE="datanode"
    else
        NODE="datanode$i"
    fi
    docker ps | grep $NODE
    if [ $? -eq 0 ]; then
        echo "âœ… $NODE estÃ¡ corriendo"
        HEALTH=$(docker inspect --format='{{.State.Health.Status}}' $NODE 2>/dev/null)
        echo "   Estado de salud: $HEALTH"
    else
        echo "âŒ $NODE NO estÃ¡ corriendo"
    fi
done
echo ""

# 5. Verificar JournalNodes
echo "ğŸ“‹ 5. Verificando JournalNodes..."
for i in 1 2 3; do
    NODE="journalnode$i"
    docker ps | grep $NODE
    if [ $? -eq 0 ]; then
        echo "âœ… $NODE estÃ¡ corriendo"
    else
        echo "âŒ $NODE NO estÃ¡ corriendo"
    fi
done
echo ""

# 6. Verificar conectividad entre servicios
echo "ğŸ“‹ 6. Verificando conectividad de red..."
docker exec namenode ping -c 2 datanode > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… NameNode puede comunicarse con DataNode"
else
    echo "âŒ Problema de conectividad NameNode -> DataNode"
fi

docker exec namenode ping -c 2 journalnode1 > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… NameNode puede comunicarse con JournalNode"
else
    echo "âŒ Problema de conectividad NameNode -> JournalNode"
fi
echo ""

# 7. Verificar logs de errores crÃ­ticos
echo "ğŸ“‹ 7. Verificando logs de errores..."
echo "   NameNode:"
docker logs namenode 2>&1 | grep -i "error\|exception\|fatal" | tail -5
echo "   DataNode:"
docker logs datanode 2>&1 | grep -i "error\|exception\|fatal" | tail -5
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 1 COMPLETADA"
echo "=========================================="
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer1_infrastructure.sh
./test_layer1_infrastructure.sh
```

---

## ğŸ§ª CAPA 2: MensajerÃ­a (Kafka)

### Componentes a probar:
- Kafka Broker 1, 2, 3
- CreaciÃ³n de topics
- ProducciÃ³n y consumo de mensajes de prueba

### Script de Prueba: `test_layer2_messaging.sh`

```bash
#!/bin/bash
# test_layer2_messaging.sh - Prueba Kafka y ZooKeeper

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 2: MENSAJERÃA (KAFKA)"
echo "=========================================="
echo ""

# 1. Verificar que Kafka brokers estÃ¡n corriendo
echo "ğŸ“‹ 1. Verificando Kafka brokers..."
for i in "" "2" "3"; do
    BROKER="kafka$i"
    docker ps | grep $BROKER
    if [ $? -eq 0 ]; then
        HEALTH=$(docker inspect --format='{{.State.Health.Status}}' $BROKER 2>/dev/null)
        echo "âœ… $BROKER estÃ¡ corriendo (health: $HEALTH)"
    else
        echo "âŒ $BROKER NO estÃ¡ corriendo"
    fi
done
echo ""

# 2. Verificar conectividad con ZooKeeper
echo "ğŸ“‹ 2. Verificando conexiÃ³n Kafka -> ZooKeeper..."
docker exec kafka kafka-broker-api-versions --bootstrap-server localhost:9092 > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Kafka broker 1 responde correctamente"
else
    echo "âŒ Kafka broker 1 NO responde"
fi
echo ""

# 3. Crear topic de prueba
echo "ğŸ“‹ 3. Creando topic de prueba 'test-topic'..."
docker exec kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --topic test-topic \
    --partitions 3 \
    --replication-factor 3 \
    --if-not-exists 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Topic 'test-topic' creado exitosamente"
else
    echo "âš ï¸  Topic puede que ya exista o hubo un error"
fi
echo ""

# 4. Listar topics
echo "ğŸ“‹ 4. Listando topics existentes..."
docker exec kafka kafka-topics --list --bootstrap-server localhost:9092
echo ""

# 5. Enviar mensaje de prueba
echo "ğŸ“‹ 5. Enviando mensaje de prueba..."
echo "test-message-$(date +%s)" | docker exec -i kafka kafka-console-producer \
    --bootstrap-server localhost:9092 \
    --topic test-topic > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Mensaje enviado correctamente"
else
    echo "âŒ Error al enviar mensaje"
fi
echo ""

# 6. Consumir mensaje de prueba
echo "ğŸ“‹ 6. Consumiendo mensaje de prueba..."
timeout 5 docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic test-topic \
    --from-beginning \
    --max-messages 1 2>&1 | grep -q "test-message" && echo "âœ… Mensaje recibido correctamente" || echo "âš ï¸  No se recibiÃ³ mensaje"
echo ""

# 7. Verificar logs de Kafka
echo "ğŸ“‹ 7. Verificando logs de Kafka (Ãºltimos errores)..."
docker logs kafka 2>&1 | grep -i "error\|exception\|fatal" | tail -5
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 2 COMPLETADA"
echo "=========================================="
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer2_messaging.sh
./test_layer2_messaging.sh
```

---

## ğŸ§ª CAPA 3: ProducciÃ³n (Producer)

### Componentes a probar:
- Producer Python
- ConexiÃ³n a Kafka
- EnvÃ­o de mensajes al topic correcto
- Formato de mensajes JSON

### Script de Prueba: `test_layer3_producer.sh`

```bash
#!/bin/bash
# test_layer3_producer.sh - Prueba el Producer

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 3: PRODUCCIÃ“N (PRODUCER)"
echo "=========================================="
echo ""

# 1. Verificar que Producer estÃ¡ corriendo
echo "ğŸ“‹ 1. Verificando Producer..."
docker ps | grep producer
if [ $? -eq 0 ]; then
    echo "âœ… Producer estÃ¡ corriendo"
else
    echo "âŒ Producer NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 2. Verificar logs del Producer (Ãºltimos 20 lÃ­neas)
echo "ğŸ“‹ 2. Verificando logs del Producer..."
echo "   Ãšltimos mensajes enviados:"
docker logs producer --tail 20 2>&1 | grep "ğŸ“¤ Enviado:" | tail -5
if [ $? -eq 0 ]; then
    echo "âœ… Producer estÃ¡ enviando mensajes"
else
    echo "âš ï¸  No se encontraron mensajes enviados en los logs"
fi
echo ""

# 3. Verificar errores en logs
echo "ğŸ“‹ 3. Verificando errores en logs del Producer..."
ERRORS=$(docker logs producer 2>&1 | grep -i "error\|exception\|failed" | tail -5)
if [ -z "$ERRORS" ]; then
    echo "âœ… No se encontraron errores"
else
    echo "âš ï¸  Errores encontrados:"
    echo "$ERRORS"
fi
echo ""

# 4. Verificar que el Producer puede conectarse a Kafka
echo "ğŸ“‹ 4. Verificando conectividad Producer -> Kafka..."
docker exec producer python3 -c "
import socket
import sys
try:
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    result = sock.connect_ex(('kafka', 9092))
    sock.close()
    if result == 0:
        print('âœ… Producer puede conectarse a Kafka:9092')
        sys.exit(0)
    else:
        print('âŒ Producer NO puede conectarse a Kafka:9092')
        sys.exit(1)
except Exception as e:
    print(f'âŒ Error de conexiÃ³n: {e}')
    sys.exit(1)
"
echo ""

# 5. Verificar que hay mensajes en el topic
echo "ğŸ“‹ 5. Verificando mensajes en topic 'energy_stream'..."
COUNT=$(timeout 3 docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic energy_stream \
    --from-beginning \
    --max-messages 10 2>&1 | wc -l)
if [ $COUNT -gt 0 ]; then
    echo "âœ… Hay mensajes en el topic (al menos $COUNT mensajes)"
else
    echo "âš ï¸  No se encontraron mensajes en el topic"
fi
echo ""

# 6. Verificar formato JSON de un mensaje
echo "ğŸ“‹ 6. Verificando formato JSON de mensajes..."
SAMPLE=$(timeout 3 docker exec kafka kafka-console-consumer \
    --bootstrap-server localhost:9092 \
    --topic energy_stream \
    --from-beginning \
    --max-messages 1 2>&1 | tail -1)
if echo "$SAMPLE" | python3 -m json.tool > /dev/null 2>&1; then
    echo "âœ… Formato JSON vÃ¡lido"
    echo "   Muestra: ${SAMPLE:0:100}..."
else
    echo "âŒ Formato JSON invÃ¡lido"
    echo "   Muestra: $SAMPLE"
fi
echo ""

# 7. Verificar estructura del mensaje
echo "ğŸ“‹ 7. Verificando estructura del mensaje..."
if echo "$SAMPLE" | python3 -c "
import json
import sys
try:
    data = json.load(sys.stdin)
    required = ['datetime', 'global_active_power', 'voltage']
    missing = [f for f in required if f not in data]
    if missing:
        print(f'âŒ Campos faltantes: {missing}')
        sys.exit(1)
    else:
        print('âœ… Estructura del mensaje correcta')
        print(f'   Campos: {list(data.keys())}')
        sys.exit(0)
except Exception as e:
    print(f'âŒ Error parseando JSON: {e}')
    sys.exit(1)
" 2>&1; then
    echo ""
else
    echo "âš ï¸  Problema con la estructura del mensaje"
fi
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 3 COMPLETADA"
echo "=========================================="
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer3_producer.sh
./test_layer3_producer.sh
```

---

## ğŸ§ª CAPA 4: Consumo (Spark Consumer)

### Componentes a probar:
- Spark Consumer
- ConexiÃ³n a Kafka
- Lectura de mensajes
- Escritura a HDFS
- TransformaciÃ³n de datos

### Script de Prueba: `test_layer4_consumer.sh`

```bash
#!/bin/bash
# test_layer4_consumer.sh - Prueba el Spark Consumer

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 4: CONSUMO (SPARK CONSUMER)"
echo "=========================================="
echo ""

# 1. Verificar que Consumer estÃ¡ corriendo
echo "ğŸ“‹ 1. Verificando Spark Consumer..."
docker ps | grep spark-consumer
if [ $? -eq 0 ]; then
    echo "âœ… Spark Consumer estÃ¡ corriendo"
else
    echo "âŒ Spark Consumer NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 2. Verificar logs del Consumer
echo "ğŸ“‹ 2. Verificando logs del Consumer..."
echo "   Estado del consumer:"
docker logs spark-consumer --tail 30 2>&1 | grep -E "Consumer iniciado|Procesando|Leyendo|Transformando|Escribiendo|Error|Exception" | tail -10
echo ""

# 3. Verificar errores crÃ­ticos
echo "ğŸ“‹ 3. Verificando errores en logs..."
ERRORS=$(docker logs spark-consumer 2>&1 | grep -i "error\|exception\|fatal\|failed" | tail -10)
if [ -z "$ERRORS" ]; then
    echo "âœ… No se encontraron errores crÃ­ticos"
else
    echo "âš ï¸  Errores encontrados:"
    echo "$ERRORS"
fi
echo ""

# 4. Verificar descarga de dependencias
echo "ğŸ“‹ 4. Verificando descarga de dependencias..."
if docker logs spark-consumer 2>&1 | grep -q "hadoop-client-api.*jar"; then
    echo "âœ… Dependencias descargadas correctamente"
else
    echo "âš ï¸  Verificando estado de dependencias..."
    docker exec spark-consumer ls -la /root/.ivy2/jars/ | grep -E "kafka|hadoop" | head -5
fi
echo ""

# 5. Verificar conexiÃ³n Consumer -> Kafka
echo "ğŸ“‹ 5. Verificando conectividad Consumer -> Kafka..."
docker exec spark-consumer nc -zv kafka 9092 > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Consumer puede conectarse a Kafka"
else
    echo "âŒ Consumer NO puede conectarse a Kafka"
fi
echo ""

# 6. Verificar conexiÃ³n Consumer -> HDFS
echo "ğŸ“‹ 6. Verificando conectividad Consumer -> HDFS..."
docker exec spark-consumer nc -zv namenode 9000 > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Consumer puede conectarse a HDFS"
else
    echo "âŒ Consumer NO puede conectarse a HDFS"
fi
echo ""

# 7. Verificar datos en HDFS
echo "ğŸ“‹ 7. Verificando datos escritos en HDFS..."
HDFS_PATH="/user/amalia/energy_data/streaming"
docker exec namenode curl -s "http://localhost:9870/webhdfs/v1${HDFS_PATH}?op=LISTSTATUS" 2>&1 | python3 -m json.tool > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Hay datos en HDFS en $HDFS_PATH"
    echo "   Estructura:"
    docker exec namenode curl -s "http://localhost:9870/webhdfs/v1${HDFS_PATH}?op=LISTSTATUS" 2>&1 | python3 -c "
import json, sys
data = json.load(sys.stdin)
if 'FileStatuses' in data:
    for f in data['FileStatuses']['FileStatus'][:5]:
        print(f\"   - {f.get('pathSuffix', 'root')} ({f.get('type', 'UNKNOWN')})\")
" 2>&1
else
    echo "âš ï¸  No se encontraron datos en HDFS o hay un error de acceso"
fi
echo ""

# 8. Verificar Spark UI
echo "ğŸ“‹ 8. Verificando Spark UI..."
docker exec spark-consumer curl -s http://localhost:4040 > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Spark UI estÃ¡ accesible"
else
    echo "âš ï¸  Spark UI no estÃ¡ accesible (puede estar en otro puerto)"
    docker exec spark-consumer netstat -tlnp 2>/dev/null | grep 404
fi
echo ""

# 9. Verificar procesos Spark
echo "ğŸ“‹ 9. Verificando procesos Spark..."
docker exec spark-consumer ps aux | grep -E "spark|java.*SparkSubmit" | grep -v grep | head -3
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 4 COMPLETADA"
echo "=========================================="
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer4_consumer.sh
./test_layer4_consumer.sh
```

---

## ğŸ§ª CAPA 5: Almacenamiento (HDFS + Hive)

### Componentes a probar:
- Datos en HDFS (formato Parquet)
- Hive Metastore
- Consultas SQL sobre datos

### Script de Prueba: `test_layer5_storage.sh`

```bash
#!/bin/bash
# test_layer5_storage.sh - Prueba HDFS y Hive

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 5: ALMACENAMIENTO (HDFS + HIVE)"
echo "=========================================="
echo ""

# 1. Verificar Hive Metastore
echo "ğŸ“‹ 1. Verificando Hive Metastore..."
docker ps | grep hive-metastore
if [ $? -eq 0 ]; then
    echo "âœ… Hive Metastore estÃ¡ corriendo"
    docker exec spark-consumer nc -zv hive-metastore 9083 > /dev/null 2>&1
    if [ $? -eq 0 ]; then
        echo "âœ… Puerto 9083 accesible"
    else
        echo "âŒ Puerto 9083 NO accesible"
    fi
else
    echo "âŒ Hive Metastore NO estÃ¡ corriendo"
fi
echo ""

# 2. Verificar datos Parquet en HDFS
echo "ğŸ“‹ 2. Verificando datos Parquet en HDFS..."
HDFS_PATH="/user/amalia/energy_data/streaming"
RESPONSE=$(docker exec namenode curl -s "http://localhost:9870/webhdfs/v1${HDFS_PATH}?op=LISTSTATUS" 2>&1)
if echo "$RESPONSE" | python3 -m json.tool > /dev/null 2>&1; then
    echo "âœ… Path de HDFS accesible"
    COUNT=$(echo "$RESPONSE" | python3 -c "
import json, sys
data = json.load(sys.stdin)
if 'FileStatuses' in data:
    print(len(data['FileStatuses']['FileStatus']))
else:
    print(0)
" 2>&1)
    echo "   Archivos/directorios encontrados: $COUNT"
else
    echo "âŒ Error accediendo a HDFS"
    echo "   Respuesta: ${RESPONSE:0:200}"
fi
echo ""

# 3. Verificar estructura de particiones
echo "ğŸ“‹ 3. Verificando estructura de particiones..."
docker exec namenode curl -s "http://localhost:9870/webhdfs/v1${HDFS_PATH}?op=LISTSTATUS" 2>&1 | python3 -c "
import json, sys
data = json.load(sys.stdin)
if 'FileStatuses' in data:
    partitions = [f['pathSuffix'] for f in data['FileStatuses']['FileStatus'] if f.get('type') == 'DIRECTORY']
    if partitions:
        print('âœ… Particiones encontradas:')
        for p in partitions[:5]:
            print(f'   - {p}')
    else:
        print('âš ï¸  No se encontraron particiones')
" 2>&1
echo ""

# 4. Ejecutar query de prueba con Spark SQL
echo "ğŸ“‹ 4. Ejecutando query de prueba (contar registros)..."
QUERY="SELECT COUNT(*) as total FROM parquet.\`hdfs://namenode:9000${HDFS_PATH}\`"
docker exec spark-consumer /opt/spark/bin/spark-submit \
    --master local[1] \
    --driver-memory 512m \
    --executor-memory 512m \
    --conf spark.hadoop.fs.defaultFS=hdfs://namenode:9000 \
    /app/consumer/spark_query.py "$QUERY" "hdfs://namenode:9000" 2>&1 | tail -5
echo ""

# 5. Verificar tabla Hive (si existe)
echo "ğŸ“‹ 5. Verificando tabla Hive..."
docker exec spark-consumer /opt/spark/bin/spark-submit \
    --master local[1] \
    --driver-memory 512m \
    --conf spark.hadoop.fs.defaultFS=hdfs://namenode:9000 \
    --conf spark.sql.catalogImplementation=hive \
    --conf hive.metastore.uris=thrift://hive-metastore:9083 \
    -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Test').enableHiveSupport().getOrCreate()
try:
    spark.sql('SHOW TABLES').show()
    print('âœ… Tablas Hive accesibles')
except Exception as e:
    print(f'âš ï¸  Error accediendo a Hive: {e}')
spark.stop()
" 2>&1 | tail -5
echo ""

# 6. Verificar formato Parquet
echo "ğŸ“‹ 6. Verificando formato Parquet..."
# Intentar leer un archivo Parquet
docker exec spark-consumer /opt/spark/bin/spark-submit \
    --master local[1] \
    --driver-memory 512m \
    --conf spark.hadoop.fs.defaultFS=hdfs://namenode:9000 \
    -c "
from pyspark.sql import SparkSession
spark = SparkSession.builder.appName('Test').getOrCreate()
try:
    df = spark.read.parquet('hdfs://namenode:9000${HDFS_PATH}')
    print(f'âœ… Formato Parquet vÃ¡lido')
    print(f'   Columnas: {df.columns}')
    print(f'   Registros: {df.count()}')
except Exception as e:
    print(f'âŒ Error leyendo Parquet: {e}')
spark.stop()
" 2>&1 | tail -5
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 5 COMPLETADA"
echo "=========================================="
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer5_storage.sh
./test_layer5_storage.sh
```

---

## ğŸ§ª CAPA 6: VisualizaciÃ³n (Dashboard)

### Componentes a probar:
- Dashboard Flask
- APIs REST
- Lectura de datos desde HDFS
- VisualizaciÃ³n en navegador

### Script de Prueba: `test_layer6_dashboard.sh`

```bash
#!/bin/bash
# test_layer6_dashboard.sh - Prueba el Dashboard

echo "=========================================="
echo "ğŸ§ª PRUEBA CAPA 6: VISUALIZACIÃ“N (DASHBOARD)"
echo "=========================================="
echo ""

# 1. Verificar que Dashboard estÃ¡ corriendo
echo "ğŸ“‹ 1. Verificando Dashboard..."
docker ps | grep dashboard
if [ $? -eq 0 ]; then
    echo "âœ… Dashboard estÃ¡ corriendo"
else
    echo "âŒ Dashboard NO estÃ¡ corriendo"
    exit 1
fi
echo ""

# 2. Verificar puerto del Dashboard
echo "ğŸ“‹ 2. Verificando puerto del Dashboard..."
PORT=$(docker port dashboard | cut -d: -f2)
if [ ! -z "$PORT" ]; then
    echo "âœ… Dashboard escuchando en puerto $PORT"
    curl -s http://localhost:$PORT > /dev/null 2>&1
    if [ $? -eq 0 ]; then
        echo "âœ… Dashboard accesible vÃ­a HTTP"
    else
        echo "âŒ Dashboard NO accesible vÃ­a HTTP"
    fi
else
    echo "âŒ No se pudo determinar el puerto"
fi
echo ""

# 3. Probar API de health check
echo "ğŸ“‹ 3. Probando API /api/health..."
HEALTH=$(curl -s http://localhost:$PORT/api/health 2>&1)
if echo "$HEALTH" | grep -q "healthy"; then
    echo "âœ… Health check exitoso"
    echo "   Respuesta: $HEALTH"
else
    echo "âš ï¸  Health check fallÃ³ o respuesta inesperada"
    echo "   Respuesta: $HEALTH"
fi
echo ""

# 4. Probar API /api/latest
echo "ğŸ“‹ 4. Probando API /api/latest..."
LATEST=$(curl -s http://localhost:$PORT/api/latest 2>&1)
if echo "$LATEST" | python3 -m json.tool > /dev/null 2>&1; then
    COUNT=$(echo "$LATEST" | python3 -c "import json,sys; d=json.load(sys.stdin); print(d.get('count', 0))" 2>&1)
    if [ "$COUNT" -gt 0 ]; then
        echo "âœ… API /api/latest funciona (retornÃ³ $COUNT registros)"
    else
        echo "âš ï¸  API /api/latest funciona pero no hay datos"
    fi
else
    echo "âŒ API /api/latest retornÃ³ respuesta invÃ¡lida"
    echo "   Respuesta: ${LATEST:0:200}"
fi
echo ""

# 5. Probar API /api/statistics
echo "ğŸ“‹ 5. Probando API /api/statistics..."
STATS=$(curl -s http://localhost:$PORT/api/statistics 2>&1)
if echo "$STATS" | python3 -m json.tool > /dev/null 2>&1; then
    echo "âœ… API /api/statistics funciona"
    echo "   EstadÃ­sticas:"
    echo "$STATS" | python3 -c "
import json, sys
data = json.load(sys.stdin)
if 'data' in data:
    for k, v in data['data'].items():
        print(f'   - {k}: {v}')
" 2>&1
else
    echo "âŒ API /api/statistics retornÃ³ respuesta invÃ¡lida"
fi
echo ""

# 6. Probar API /api/timeseries
echo "ğŸ“‹ 6. Probando API /api/timeseries..."
TIMESERIES=$(curl -s http://localhost:$PORT/api/timeseries 2>&1)
if echo "$TIMESERIES" | python3 -m json.tool > /dev/null 2>&1; then
    COUNT=$(echo "$TIMESERIES" | python3 -c "import json,sys; d=json.load(sys.stdin); print(d.get('count', 0))" 2>&1)
    echo "âœ… API /api/timeseries funciona (retornÃ³ $COUNT puntos)"
else
    echo "âŒ API /api/timeseries retornÃ³ respuesta invÃ¡lida"
fi
echo ""

# 7. Verificar logs del Dashboard
echo "ğŸ“‹ 7. Verificando logs del Dashboard..."
echo "   Ãšltimas peticiones:"
docker logs dashboard --tail 20 2>&1 | grep "GET\|POST" | tail -5
echo ""

# 8. Verificar errores en logs
echo "ğŸ“‹ 8. Verificando errores en logs..."
ERRORS=$(docker logs dashboard 2>&1 | grep -i "error\|exception\|failed" | tail -5)
if [ -z "$ERRORS" ]; then
    echo "âœ… No se encontraron errores"
else
    echo "âš ï¸  Errores encontrados:"
    echo "$ERRORS"
fi
echo ""

# 9. Verificar conectividad Dashboard -> Spark Consumer
echo "ğŸ“‹ 9. Verificando conectividad Dashboard -> Spark Consumer..."
docker exec dashboard ping -c 2 spark-consumer > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Dashboard puede comunicarse con Spark Consumer"
else
    echo "âŒ Dashboard NO puede comunicarse con Spark Consumer"
fi
echo ""

echo "=========================================="
echo "âœ… PRUEBA CAPA 6 COMPLETADA"
echo "=========================================="
echo ""
echo "ğŸŒ Dashboard disponible en: http://localhost:$PORT"
```

### Comandos para ejecutar:
```bash
cd docker
chmod +x test_layer6_dashboard.sh
./test_layer6_dashboard.sh
```

---

## ğŸš€ Script Maestro: Ejecutar Todas las Pruebas

### Script: `test_all_layers.sh`

```bash
#!/bin/bash
# test_all_layers.sh - Ejecuta todas las pruebas por capas

echo "=========================================="
echo "ğŸ§ª EJECUTANDO TODAS LAS PRUEBAS POR CAPAS"
echo "=========================================="
echo ""

LAYERS=(
    "test_layer1_infrastructure.sh:Infraestructura Base"
    "test_layer2_messaging.sh:MensajerÃ­a (Kafka)"
    "test_layer3_producer.sh:ProducciÃ³n (Producer)"
    "test_layer4_consumer.sh:Consumo (Spark Consumer)"
    "test_layer5_storage.sh:Almacenamiento (HDFS + Hive)"
    "test_layer6_dashboard.sh:VisualizaciÃ³n (Dashboard)"
)

FAILED=0
PASSED=0

for layer in "${LAYERS[@]}"; do
    SCRIPT="${layer%%:*}"
    NAME="${layer##*:}"
    
    echo ""
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo "â–¶ï¸  Ejecutando: $NAME"
    echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
    echo ""
    
    if [ -f "$SCRIPT" ] && [ -x "$SCRIPT" ]; then
        ./$SCRIPT
        RESULT=$?
        if [ $RESULT -eq 0 ]; then
            echo "âœ… $NAME: PASÃ“"
            ((PASSED++))
        else
            echo "âŒ $NAME: FALLÃ“ (cÃ³digo: $RESULT)"
            ((FAILED++))
        fi
    else
        echo "âš ï¸  Script $SCRIPT no encontrado o no es ejecutable"
        ((FAILED++))
    fi
    
    sleep 2
done

echo ""
echo "=========================================="
echo "ğŸ“Š RESUMEN DE PRUEBAS"
echo "=========================================="
echo "âœ… Pruebas pasadas: $PASSED"
echo "âŒ Pruebas fallidas: $FAILED"
echo "ğŸ“ˆ Total: $((PASSED + FAILED))"
echo ""

if [ $FAILED -eq 0 ]; then
    echo "ğŸ‰ Â¡Todas las pruebas pasaron!"
    exit 0
else
    echo "âš ï¸  Algunas pruebas fallaron. Revisa los logs arriba."
    exit 1
fi
```

---

## ğŸ“ Uso

### Ejecutar pruebas individuales:
```bash
cd docker
chmod +x test_layer*.sh
./test_layer1_infrastructure.sh
./test_layer2_messaging.sh
# etc...
```

### Ejecutar todas las pruebas:
```bash
cd docker
chmod +x test_all_layers.sh
./test_all_layers.sh
```

### Ejecutar pruebas en orden incremental:
```bash
cd docker
# Primero levantar solo la capa 1
docker compose up -d zookeeper namenode namenode-standby datanode datanode2 datanode3 journalnode1 journalnode2 journalnode3
./test_layer1_infrastructure.sh

# Luego agregar capa 2
docker compose up -d kafka kafka2 kafka3
./test_layer2_messaging.sh

# Y asÃ­ sucesivamente...
```

---

## ğŸ” Logs Detallados

Para obtener logs mÃ¡s detallados de cada componente:

```bash
# Logs en tiempo real
docker logs -f <container-name>

# Logs con filtros
docker logs <container-name> 2>&1 | grep -i "error\|exception\|warn"

# Ãšltimas N lÃ­neas
docker logs <container-name> --tail 100
```

---

## ğŸ“‹ Checklist de VerificaciÃ³n

- [ ] Capa 1: Infraestructura base funcionando
- [ ] Capa 2: Kafka y ZooKeeper funcionando
- [ ] Capa 3: Producer enviando datos
- [ ] Capa 4: Consumer procesando datos
- [ ] Capa 5: Datos almacenados en HDFS
- [ ] Capa 6: Dashboard mostrando datos

