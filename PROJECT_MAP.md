# ğŸ—ºï¸ MAPA VISUAL DEL PROYECTO

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         TU COMPUTADORA                               â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                    DOCKER ENGINE                            â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚    â”‚
â”‚  â”‚  â”‚  Zookeeper   â”‚â”€â”€â”€â”€â”€â”€â”‚    Kafka     â”‚â—„â”€â”€â”€ Producer      â”‚    â”‚
â”‚  â”‚  â”‚   :2181      â”‚      â”‚    :9092     â”‚     (Python)      â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚    â”‚
â”‚  â”‚                               â”‚                            â”‚    â”‚
â”‚  â”‚                               â†“                            â”‚    â”‚
â”‚  â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚    â”‚
â”‚  â”‚                        â”‚    Spark     â”‚                   â”‚    â”‚
â”‚  â”‚                        â”‚   Consumer   â”‚                   â”‚    â”‚
â”‚  â”‚                        â”‚   :4040 UI   â”‚                   â”‚    â”‚
â”‚  â”‚                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚    â”‚
â”‚  â”‚                               â”‚                            â”‚    â”‚
â”‚  â”‚                               â†“                            â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚    â”‚
â”‚  â”‚  â”‚   NameNode   â”‚â—„â”€â”€â”€â”€â–ºâ”‚  DataNode    â”‚                   â”‚    â”‚
â”‚  â”‚  â”‚  :9870 UI    â”‚      â”‚    :9864     â”‚                   â”‚    â”‚
â”‚  â”‚  â”‚  :9000 HDFS  â”‚      â”‚              â”‚                   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚    â”‚
â”‚  â”‚         â”‚                                                  â”‚    â”‚
â”‚  â”‚         â†“                                                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚    â”‚
â”‚  â”‚  â”‚    Hive      â”‚      â”‚    YARN      â”‚                   â”‚    â”‚
â”‚  â”‚  â”‚  Metastore   â”‚      â”‚ :8088 UI     â”‚                   â”‚    â”‚
â”‚  â”‚  â”‚   :9083      â”‚      â”‚              â”‚                   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚    â”‚
â”‚  â”‚                                                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                      â”‚
â”‚  Puertos expuestos a tu navegador:                                  â”‚
â”‚  â€¢ http://localhost:9870 â† HDFS                                    â”‚
â”‚  â€¢ http://localhost:4040 â† Spark                                   â”‚
â”‚  â€¢ http://localhost:8088 â† YARN                                    â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š FLUJO DE DATOS DETALLADO

```
PASO 1: CARGA DEL DATASET
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ household_power_        â”‚
â”‚ consumption.txt         â”‚
â”‚ (127 MB, 2M registros)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ data/dataset.txt        â”‚
â”‚ (copiado por start.sh)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚
PASO 2: PRODUCER (Contenedor Python)
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ producer/data_loader.py â”‚
â”‚ â€¢ Lee CSV con Pandas    â”‚
â”‚ â€¢ Limpia nulos          â”‚
â”‚ â€¢ Crea timestamp        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ producer/               â”‚
â”‚ message_builder.py      â”‚
â”‚ â€¢ Convierte a JSON      â”‚
â”‚ {"datetime": "...",     â”‚
â”‚  "global_active_power"} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“ (cada 5 segundos)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Kafka Topic             â”‚
â”‚ "energy_stream"         â”‚
â”‚ Buffer de mensajes      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚
PASO 3: CONSUMER (Contenedor Spark)
            â”‚
            â†“ (cada 60 segundos)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ consumer/src/           â”‚
â”‚ kafka_reader.py         â”‚
â”‚ â€¢ Lee stream de Kafka   â”‚
â”‚ â€¢ Parsea JSON           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ consumer/src/           â”‚
â”‚ data_transformer.py     â”‚
â”‚ â€¢ Limpia datos          â”‚
â”‚ â€¢ Valida rangos         â”‚
â”‚ â€¢ Agrega year/month/day â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ consumer/src/           â”‚
â”‚ hdfs_writer.py          â”‚
â”‚ â€¢ Escribe a HDFS        â”‚
â”‚ â€¢ Formato: Parquet      â”‚
â”‚ â€¢ Particionado por      â”‚
â”‚   fecha/hora            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚
PASO 4: ALMACENAMIENTO (HDFS)
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HDFS Storage            â”‚
â”‚ hdfs://namenode:9000/   â”‚
â”‚ user/amalia/energy_data â”‚
â”‚ /streaming/             â”‚
â”‚                         â”‚
â”‚ year=2006/              â”‚
â”‚   month=12/             â”‚
â”‚     day=16/             â”‚
â”‚       hour=17/          â”‚
â”‚         part-xxx.parquetâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â”‚
PASO 5: HIVE (SQL sobre HDFS)
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hive Table              â”‚
â”‚ "energy_data"           â”‚
â”‚ â€¢ Tabla externa         â”‚
â”‚ â€¢ Apunta a HDFS         â”‚
â”‚ â€¢ Permite SQL           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Consultas SQL           â”‚
â”‚ SELECT * FROM           â”‚
â”‚ energy_data WHERE       â”‚
â”‚ year = 2007             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ® COMANDOS ESENCIALES

### Para iniciar todo:
```bash
./start.sh
```

### Para verificar requisitos:
```bash
./check-requirements.sh
```

### Para monitorear:
```bash
# Ver todos los contenedores
docker ps

# Ver logs del Producer
docker logs -f producer

# Ver logs del Consumer
docker logs -f spark-consumer

# Ver uso de recursos
docker stats
```

### Para verificar datos:
```bash
# Listar archivos en HDFS
docker exec namenode hdfs dfs -ls /user/amalia/energy_data/streaming/

# Ver estructura completa
docker exec namenode hdfs dfs -ls -R /user/amalia/energy_data/streaming/ | head -30

# Contar archivos
docker exec namenode hdfs dfs -count /user/amalia/energy_data/streaming/
```

### Para consultar con SQL:
```bash
# Entrar a Spark SQL
docker exec -it spark-consumer /opt/spark/bin/spark-sql --master local

# Dentro de Spark SQL:
SHOW TABLES;
SELECT COUNT(*) FROM energy_data;
SELECT * FROM energy_data LIMIT 10;
EXIT;
```

### Para detener:
```bash
cd docker

# Detener (mantiene datos)
docker compose stop

# Detener y eliminar contenedores (mantiene volÃºmenes)
docker compose down

# Eliminar TODO incluyendo datos
docker compose down -v
```

---

## ğŸ“‚ ESTRUCTURA DE ARCHIVOS

```
PLVD-Predicting-energy-consumption/
â”‚
â”œâ”€â”€ ğŸ“„ README.md                    â† DescripciÃ³n general
â”œâ”€â”€ ğŸ“„ QUICK_START.md              â† Esta guÃ­a (inicio rÃ¡pido)
â”œâ”€â”€ ğŸ“„ INSTALLATION_GUIDE.md       â† InstalaciÃ³n completa
â”œâ”€â”€ ğŸ”§ check-requirements.sh       â† Verifica requisitos
â”œâ”€â”€ ğŸš€ start.sh                    â† Inicia todo automÃ¡ticamente
â”‚
â”œâ”€â”€ ğŸ“ data/
â”‚   â””â”€â”€ dataset.txt                â† Dataset (127 MB)
â”‚
â”œâ”€â”€ ğŸ“ producer/                   â† CÃ³digo del Producer
â”‚   â”œâ”€â”€ producer.py                â† Script principal
â”‚   â”œâ”€â”€ data_loader.py             â† Carga CSV
â”‚   â”œâ”€â”€ message_builder.py         â† Crea JSON
â”‚   â”œâ”€â”€ kafka_client.py            â† EnvÃ­a a Kafka
â”‚   â”œâ”€â”€ config.py                  â† ConfiguraciÃ³n
â”‚   â””â”€â”€ requirements.txt           â† Dependencias Python
â”‚
â”œâ”€â”€ ğŸ“ consumer/                   â† CÃ³digo del Consumer
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ consumer.py            â† Script principal Spark
â”‚       â”œâ”€â”€ kafka_reader.py        â† Lee de Kafka
â”‚       â”œâ”€â”€ data_transformer.py    â† Transforma datos
â”‚       â”œâ”€â”€ hdfs_writer.py         â† Escribe a HDFS
â”‚       â”œâ”€â”€ hive_connector.py      â† Configura Hive
â”‚       â””â”€â”€ config.py              â† ConfiguraciÃ³n
â”‚
â”œâ”€â”€ ğŸ“ docker/                     â† ConfiguraciÃ³n Docker
â”‚   â”œâ”€â”€ docker-compose.yml         â† Define todos los servicios
â”‚   â”œâ”€â”€ init-hdfs.sh               â† Inicializa HDFS
â”‚   â”œâ”€â”€ FIXES_APPLIED.md           â† Correcciones aplicadas
â”‚   â””â”€â”€ spark-consumer/
â”‚       â””â”€â”€ Dockerfile             â† Imagen de Spark
â”‚
â”œâ”€â”€ ğŸ“ spark_jobs/                 â† Jobs de anÃ¡lisis
â”‚   â”œâ”€â”€ features.py                â† Feature engineering
â”‚   â”œâ”€â”€ clean_data.py              â† Limpieza de datos
â”‚   â””â”€â”€ query_examples.py          â† Ejemplos de consultas
â”‚
â””â”€â”€ ğŸ“ board/                      â† Dashboard (pendiente)
    â””â”€â”€ app.py                     â† AplicaciÃ³n web
```

---

## â±ï¸ TIMELINE DE EJECUCIÃ“N

```
Tiempo    Evento
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
00:00     ./start.sh ejecutado
00:05     Docker construyendo imÃ¡genes...
00:10     ImÃ¡genes construidas
00:15     Zookeeper iniciado
00:20     Kafka iniciado (esperando healthy)
00:30     HDFS iniciado (NameNode + DataNode)
00:45     Kafka healthy âœ“
00:50     HDFS healthy âœ“
00:55     init-hdfs.sh ejecutado
01:00     Directorios HDFS creados âœ“
01:05     Producer iniciado
01:10     Consumer (Spark) iniciado
01:20     Producer enviando primer mensaje
01:25     Producer enviando segundo mensaje
01:30     Producer enviando tercer mensaje
01:35     Consumer procesa primer batch (3 mensajes)
01:40     Datos escritos en HDFS âœ“
02:00     Tabla Hive disponible âœ“
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

A partir de aquÃ­:
â€¢ Producer envÃ­a 1 mensaje cada 5 segundos
â€¢ Consumer procesa batch cada 60 segundos
â€¢ Datos se acumulan en HDFS continuamente
```

---

## ğŸ”¢ ESTADÃSTICAS DEL PROYECTO

**Dataset:**
- TamaÃ±o: 127 MB
- Registros: 2,075,259
- Periodo: 2006-2010 (4 aÃ±os)
- Granularidad: 1 minuto

**Procesamiento:**
- Velocidad de envÃ­o: 1 mensaje / 5 segundos = 12 msg/min
- Velocidad de procesamiento: Batch cada 60 segundos
- Formato almacenamiento: Parquet (comprimido ~10x)
- Particionado: AÃ±o â†’ Mes â†’ DÃ­a â†’ Hora

**Recursos:**
- Contenedores: 10
- RAM recomendada: 8 GB
- Disco: ~20 GB
- CPU: 4 cores

**Puertos:**
- 2181: Zookeeper
- 9092: Kafka
- 9870: HDFS Web UI
- 9000: HDFS
- 4040: Spark UI
- 8088: YARN UI
- 9083: Hive Metastore

---

## ğŸ¯ CHECKLIST DE VERIFICACIÃ“N

Completa despuÃ©s de ejecutar `./start.sh`:

### Servicios Base (primeros 2 minutos)
- [ ] Zookeeper corriendo: `docker ps | grep zookeeper`
- [ ] Kafka healthy: `docker ps | grep kafka` â†’ debe decir "(healthy)"
- [ ] NameNode healthy: `docker ps | grep namenode` â†’ debe decir "(healthy)"
- [ ] DataNode healthy: `docker ps | grep datanode` â†’ debe decir "(healthy)"

### Servicios de Procesamiento (minutos 3-5)
- [ ] Producer corriendo: `docker ps | grep producer`
- [ ] Consumer corriendo: `docker ps | grep spark-consumer`
- [ ] Hive corriendo: `docker ps | grep hive`
- [ ] YARN corriendo: `docker ps | grep yarn` o `resourcemanager`

### Funcionalidad (despuÃ©s de 5 minutos)
- [ ] Producer enviando: `docker logs producer | grep "Enviado:"`
- [ ] Consumer iniciado: `docker logs spark-consumer | grep "Consumer iniciado"`
- [ ] HDFS accesible: Abrir http://localhost:9870
- [ ] Directorios creados: `docker exec namenode hdfs dfs -ls /user/amalia/`
- [ ] Datos en HDFS: `docker exec namenode hdfs dfs -ls /user/amalia/energy_data/streaming/`
- [ ] Archivos Parquet: DeberÃ­as ver archivos `.parquet` en HDFS

### Interfaces Web
- [ ] HDFS UI funciona: http://localhost:9870
- [ ] Spark UI funciona: http://localhost:4040
- [ ] YARN UI funciona: http://localhost:8088

---

## ğŸ†˜ AYUDA RÃPIDA

**Â¿Algo no funciona?**

1. Ver logs: `docker logs <nombre-contenedor>`
2. Verificar estado: `docker ps`
3. Reiniciar servicio: `docker compose restart <servicio>`
4. Reiniciar todo: `cd docker && docker compose restart`
5. Limpiar y reiniciar: `docker compose down && ./start.sh`

**Â¿Contenedor no estÃ¡ "healthy"?**
```bash
# Ver detalles del healthcheck
docker inspect <nombre-contenedor> | grep -A 20 Health
```

**Â¿Puerto ocupado?**
```bash
# Ver quÃ© usa el puerto
sudo lsof -i :<numero-puerto>
```

---

Â¡Ã‰xito! ğŸ‰
